{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "369615390966991855cb10f07893fe152daad3bf3b7345eb5d99e6ac3f226e36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\r\n",
    "#Reading an image\r\n",
    "img=cv2.imread(\"resources/image.jpg\")\r\n",
    "cv2.imshow(\"output\",img)\r\n",
    "cv2.waitKey(2000)#provinding a delay of 2 sec\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\r\n",
    "#reading vedio from device\r\n",
    "cap=cv2.VideoCapture(\"resources/vedio.mp4\")\r\n",
    "#displaying vedio frame by frame\r\n",
    "while True:\r\n",
    "    sucess,img=cap.read()\r\n",
    "    cv2.imshow(\"Output\",img)\r\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\r\n",
    "        break\r\n",
    "cv2.destroyAllWindows()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import cv2\r\n",
    "#Reading vedio from webcam\r\n",
    "cap=cv2.VideoCapture(0)\r\n",
    "cap.set(3,640)\r\n",
    "cap.set(4,640)\r\n",
    "while True:\r\n",
    "    sucess,img=cap.read()\r\n",
    "    cv2.imshow(\"Output\",img)\r\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\r\n",
    "        cap.release()\r\n",
    "        cv2.destroyAllWindows()\r\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "kernel=np.ones((5,5),np.uint8)#creates a 5 x 5 matrix and fills all values with one, type of values is unsigned 8 bit integer values\r\n",
    "img=cv2.imread(\"resources/image.jpg\")\r\n",
    "#Converting image to grayscale\r\n",
    "grayImg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\r\n",
    "#blurring the image\r\n",
    "blur_img=cv2.GaussianBlur(grayImg,(7,7),0)#(image,ksize,sigmax)\r\n",
    "#Detecting edges of the image\r\n",
    "edge_img=cv2.Canny(img,100,100)#(image,threshold1,threshold2)\r\n",
    "#image dialation is making the dges prominent and thicker\r\n",
    "dialation_img=cv2.dilate(edge_img,kernel,iterations=1)#kernal here is the matrix which detects the edges to be made prominent\r\n",
    "#opposite of dialation is erosion where the edges are made thinner\r\n",
    "eroded_img=cv2.erode(dialation_img,kernel,iterations=1)\r\n",
    "cv2.imshow(\"Gray_Image\",grayImg)\r\n",
    "cv2.waitKey(1000)\r\n",
    "cv2.imshow(\"Blur image\",blur_img)\r\n",
    "cv2.waitKey(1000)\r\n",
    "cv2.imshow(\"Edges\",edge_img)\r\n",
    "cv2.waitKey(1000)\r\n",
    "cv2.imshow(\"Dialated image\",dialation_img)\r\n",
    "cv2.waitKey(1000)\r\n",
    "cv2.imshow(\"Eroded image\",eroded_img)\r\n",
    "cv2.waitKey(1000)\r\n",
    "cv2.destroyAllWindows()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "img=cv2.imread(\"resources/image.jpg\")\n",
    "print(img.shape)#displays the shape of the image in the format(width,height,no of colors combinations use(3 for BGR))\n",
    "resized_img=cv2.resize(img,(200,200))#reizing the image by specifying the (width,height)\n",
    "#cropping the image\n",
    "cropped_img=img[0:1000,200:700]#***here the order for slicing is(height,width) and not (width,height)\n",
    "cv2.imshow(\"Resized img\",resized_img)\n",
    "cv2.waitKey(2000)\n",
    "cv2.imshow(\"cropped img\",cropped_img)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.zeros((512,512,3),np.uint8)#Creating a blank matrix with all cells filled with zer0\n",
    "#here 3 is declaring that we are giving three color chanels\n",
    "#coloring the image\n",
    "img[:]=255,0,0#here full image is colored (B,G,R)\n",
    "img[200:300,200:300]=0,255,0#here a part of the image is colored\n",
    "#drawing the line\n",
    "cv2.line(img,(0,0),(300,300),(0,0,255),3)#(image,starting pt,ending pt,color,thickness)\n",
    "cv2.line(img,(100,110),(img.shape[0],img.shape[1]),(100,100,150),2)\n",
    "cv2.imshow(\"Black_imag\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "#making  a rectangle\n",
    "cv2.rectangle(img,(0,0),(300,300),(0,0,255),3)#(image,start,end,color,thickness)\n",
    "cv2.rectangle(img,(0,0),(300,300),(0,255,0),cv2.FILLED)#instead of mentioning thickness we write cv2.Filled which fills the rectangle\n",
    "#drawing a circle\n",
    "cv2.circle(img,(400,50),30,(255,255,0),3)#(image,centre,radius,color,thickness) we can even fill the circle with color similar to rectangle\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "#adding text\n",
    "cv2.putText(img,\"Open CV\",(300,100),cv2.FONT_HERSHEY_COMPLEX,1,(0,150,0),1)#(image,text,start,font,font scale,color,thickness)\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Wrap Perspective\n",
    "#it helps to bring out a object from the image clearly out from the rest of the image\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"resources/image2.jpg\")\n",
    "width,height=250,350\n",
    "pt1=np.float32([[303,738],[728,850],[464,121],[890,233]])#cordinates in the real image\n",
    "pt2=np.float32([[0,0],[width,0],[0,height],[width,height]])#cordinates that we want to map to\n",
    "matrix=cv2.getPerspectiveTransform(pt1,pt2)#(source,destination)\n",
    "Output_img=cv2.warpPerspective(img,matrix,(width,height))#(source,destination,dsize)\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.imshow(\"WrapImg\",Output_img)\n",
    "print(Output_img.shape)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#joining the images\n",
    "#we can join images by using numpy library\n",
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(\"resources/image2.jpg\")\n",
    "img=cv2.resize(img,(200,200))\n",
    "hor_img=np.hstack([img,img])\n",
    "ver_img=np.vstack([hor_img,hor_img,hor_img])\n",
    "cv2.imshow(\"Stacked Image\",ver_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "'''here there are some disadvantages of using this method:\n",
    "1. All the images should be of the same color channel\n",
    "2. The images cannot be resized_img\n",
    "3. we cannont stack random number of picks one over another'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#color detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "def empty(a):\n",
    "    pass\n",
    "cv2.namedWindow(\"Trackbars\")#Creating a window for trackbar\n",
    "cv2.resizeWindow(\"Trackbars\",640,340)#setting size of trackbar window\n",
    "#creating trackbars for various parametres\n",
    "cv2.createTrackbar(\"Hue Min\",\"Trackbars\",13,179,empty)\n",
    "cv2.createTrackbar(\"Hue Max\",\"Trackbars\",153,179,empty)\n",
    "cv2.createTrackbar(\"Sat Min\",\"Trackbars\",34,255,empty)\n",
    "cv2.createTrackbar(\"Sat Max\",\"Trackbars\",215,255,empty)\n",
    "cv2.createTrackbar(\"Val Min\",\"Trackbars\",92,255,empty)\n",
    "cv2.createTrackbar(\"Val Max\",\"Trackbars\",250,255,empty)\n",
    "#operating a while loop for real time tracking \n",
    "while True:\n",
    "    img=cv2.imread(\"resources/image3.jpg\")\n",
    "    img=cv2.resize(img,(400,400))\n",
    "    HSV_img=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)#creating a HSV image of the original image\n",
    "    #Noting down the values of various parameters\n",
    "    h_min=cv2.getTrackbarPos(\"Hue Min\",\"Trackbars\")\n",
    "    h_max=cv2.getTrackbarPos(\"Hue Max\",\"Trackbars\")\n",
    "    s_min=cv2.getTrackbarPos(\"Sat Min\",\"Trackbars\")\n",
    "    s_max=cv2.getTrackbarPos(\"Sat Max\",\"Trackbars\")\n",
    "    v_min=cv2.getTrackbarPos(\"Val Min\",\"Trackbars\")\n",
    "    v_max=cv2.getTrackbarPos(\"Val Max\",\"Trackbars\")\n",
    "    lower=np.array([h_min,s_min,v_min])#an array of minimum values of the parameters\n",
    "    upper=np.array([h_max,s_max,v_max])#creating an array of maximum value of the parameters\n",
    "    mask=cv2.inRange(HSV_img,lower,upper)#masking HSV image between the upper and lower values of the HSV\n",
    "    finalImg=cv2.bitwise_and(img,img,mask=mask)#performing a bitwise and operation between masked image an original image to produce the detected photo color\n",
    "    cv2.imshow(\"original\",img)\n",
    "    cv2.imshow(\"HSV\",HSV_img)\n",
    "    cv2.imshow(\"Mask\",mask)\n",
    "    cv2.imshow(\"Fianl Product\",finalImg)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "       cv2.destroyAllWindows()\n",
    "       break\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#countours/shape detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "def getCountours(img):\n",
    "    contours,hierarchy=cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area=cv2.contourArea(cnt)\n",
    "        print(area)\n",
    "        cv2.drawContours(imgContour,cnt,-1,(100,255,100),5)\n",
    "        peri=cv2.arcLength(cnt,True)\n",
    "        print(peri)\n",
    "        approxCorners=cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "        print(len(approxCorners))\n",
    "        corner=len(approxCorners)\n",
    "        x,y,w,h=cv2.boundingRect(approxCorners) \n",
    "        if corner==3:\n",
    "            objectType=\"Triangle\"\n",
    "        elif corner==4:\n",
    "            aspectRatio=w/float(h)\n",
    "            if aspectRatio>0.95 and aspectRatio<1.05:\n",
    "                objectType=\"square\"\n",
    "            else:\n",
    "                objectType=\"rectangle\"\n",
    "        elif corner>4:\n",
    "            objectType=\"circle\" \n",
    "        else:\n",
    "            objectType=\"NONE\"\n",
    "        cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "        cv2.putText(imgContour,objectType,(x+(w//2-40),y+h+20),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),2)\n",
    "img=cv2.imread(\"resources/image4.jpg\")\n",
    "imgContour=img.copy()\n",
    "GrayImg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "BlurImg=cv2.GaussianBlur(GrayImg,(7,7),1)\n",
    "edgeImg=cv2.Canny(BlurImg,50,50)\n",
    "getCountours(edgeImg)\n",
    "cv2.imshow(\"Processed image\",imgContour)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#detecting faces using cascade\n",
    "import cv2\n",
    "img=cv2.imread(\"resources/image5.jpg\")\n",
    "grayImg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faceCascade=cv2.CascadeClassifier(\"resources/haarcascade_frontalface_default.xml\")\n",
    "faces=faceCascade.detectMultiScale(grayImg,1.1,10)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "cv2.imshow(\"Face \",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#detecting face on webcam\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,650)\n",
    "cap.set(4,550)\n",
    "cap.set(10,100)\n",
    "faceCascade=cv2.CascadeClassifier(\"resources/haarcascade_frontalface_default.xml\")\n",
    "while True:\n",
    "    sucess,img=cap.read()\n",
    "    grayImg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=faceCascade.detectMultiScale(grayImg,1.1,3)\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    cv2.imshow(\"Faces\",img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows() \n",
    "        break\n",
    "\n",
    "       "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}